{"backend_state":"running","connection_file":"/projects/9f552ddb-0255-4438-a179-8f8c475cfce3/.local/share/jupyter/runtime/kernel-48fa3494-aee8-478b-9a64-442917a7940e.json","kernel":"cv_env","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"CV_Classification_skeletonized.ipynb","provenance":[]},"interpreter":{"hash":"f92c92cb1bbf690c4549d4feaa58ef087288670a9e11f4f2bc1ea394ea8a7720"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"09985f7b880f47509081c7b8f6e797a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d71d754be2be425ca24b194a2aea125c","placeholder":"​","style":"IPY_MODEL_f6363bc40f524f2ea0ecb199cd4ad414","value":""}},"0c32afe2a35c48dc81e26f43832e5528":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_80c324bd3a774d9fb3474fea9a2f37a1","IPY_MODEL_d994ef5592444f078eb0b38adbb24176","IPY_MODEL_bd1bcd5f50a248a896285f4a8e154c6c"],"layout":"IPY_MODEL_86fbff3d1b4f4fe98ef4f5713c5c6014"}},"0dd8ab643bd24b2e949e4e3b4096d4be":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14bbc869fe8d452692a6f7cdb38b075b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"161da13e65934d7f9ee9e5cd9f35a46f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"20182c64d4de4aff830441867cfd9d78":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2cdcdd80797f42659fb44a03e3bbd269":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35a8bff49c89404ba666f0181606edad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37a3453775974ecd9176a3c96dde77df":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e3ac696c1ae4030970a291d0b55a9c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"499b378fe04d48aa937c21de79966c4b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a41d6fc422ee47e189be9fde8a0fa2ff","max":5148,"min":0,"orientation":"horizontal","style":"IPY_MODEL_20182c64d4de4aff830441867cfd9d78","value":5148}},"4b5790f98e3b44ec915349b854c9064f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"52dd7ed840c244059a7d69252fb20a0f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76b8caf8fcbb48779f5dea6d2329ff4d","placeholder":"​","style":"IPY_MODEL_37a3453775974ecd9176a3c96dde77df","value":" 4422656/? [00:01&lt;00:00, 3960059.28it/s]"}},"53e1b8f46e04430c8e19fb66ec674d28":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58493c17d71b43fc876c0cc4a3093120":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f4d3dce10394194943134f856a40b5e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"63bba93a02c141d18b53328db8173d67":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67167b99eabd407d8a7900319b48c67f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2cdcdd80797f42659fb44a03e3bbd269","max":4422102,"min":0,"orientation":"horizontal","style":"IPY_MODEL_71df07ea74d045ea93bba3d60dcb800c","value":4422102}},"683e7c41d782493ba3cb93d0c288ade1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68fbbf59d93340c7be0b57869ac17b15":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"701e7e3c57174353aa7190b10b10da27":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4b6729efbed4c48aa19ae019aa1ee43","placeholder":"​","style":"IPY_MODEL_c1528e5e1be64a93928ad41707b0dec0","value":" 6144/? [00:00&lt;00:00, 198807.33it/s]"}},"7151b8796109496f9a0213d2ca556296":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_58493c17d71b43fc876c0cc4a3093120","max":29515,"min":0,"orientation":"horizontal","style":"IPY_MODEL_161da13e65934d7f9ee9e5cd9f35a46f","value":29515}},"71df07ea74d045ea93bba3d60dcb800c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7280aea30eff49bf94a4217647cd70f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd2449e472514181a355fc1c315acfa2","placeholder":"​","style":"IPY_MODEL_b37cbc32dcbc49aca73006ba0f900a17","value":""}},"76b8caf8fcbb48779f5dea6d2329ff4d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80c324bd3a774d9fb3474fea9a2f37a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_35a8bff49c89404ba666f0181606edad","placeholder":"​","style":"IPY_MODEL_3e3ac696c1ae4030970a291d0b55a9c3","value":""}},"822c855d65d64f0a9112308d2389ff7c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_63bba93a02c141d18b53328db8173d67","placeholder":"​","style":"IPY_MODEL_f90246acab4b45f3b540772689ac3657","value":""}},"86fbff3d1b4f4fe98ef4f5713c5c6014":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ddf7176f4d54ae4bca347af22041b7b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_822c855d65d64f0a9112308d2389ff7c","IPY_MODEL_67167b99eabd407d8a7900319b48c67f","IPY_MODEL_52dd7ed840c244059a7d69252fb20a0f"],"layout":"IPY_MODEL_14bbc869fe8d452692a6f7cdb38b075b"}},"9e48ad9913664c5f9f53f3a815ba9c85":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_09985f7b880f47509081c7b8f6e797a6","IPY_MODEL_499b378fe04d48aa937c21de79966c4b","IPY_MODEL_701e7e3c57174353aa7190b10b10da27"],"layout":"IPY_MODEL_53e1b8f46e04430c8e19fb66ec674d28"}},"a0acaa8f8ff04fa4aa8efef789ea6094":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a41d6fc422ee47e189be9fde8a0fa2ff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b37cbc32dcbc49aca73006ba0f900a17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd1bcd5f50a248a896285f4a8e154c6c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68fbbf59d93340c7be0b57869ac17b15","placeholder":"​","style":"IPY_MODEL_fcbfca25f1a14e15b0fa0f6088bf40f1","value":" 26422272/? [00:03&lt;00:00, 11817352.68it/s]"}},"c1528e5e1be64a93928ad41707b0dec0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d4b6729efbed4c48aa19ae019aa1ee43":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d58ad2180cae45eab7addb2417b50a03":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7280aea30eff49bf94a4217647cd70f2","IPY_MODEL_7151b8796109496f9a0213d2ca556296","IPY_MODEL_d841001138284dbe8628700df81bc404"],"layout":"IPY_MODEL_683e7c41d782493ba3cb93d0c288ade1"}},"d71d754be2be425ca24b194a2aea125c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d841001138284dbe8628700df81bc404":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0acaa8f8ff04fa4aa8efef789ea6094","placeholder":"​","style":"IPY_MODEL_4b5790f98e3b44ec915349b854c9064f","value":" 29696/? [00:00&lt;00:00, 72057.25it/s]"}},"d994ef5592444f078eb0b38adbb24176":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0dd8ab643bd24b2e949e4e3b4096d4be","max":26421880,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5f4d3dce10394194943134f856a40b5e","value":26421880}},"f6363bc40f524f2ea0ecb199cd4ad414":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f90246acab4b45f3b540772689ac3657":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fcbfca25f1a14e15b0fa0f6088bf40f1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd2449e472514181a355fc1c315acfa2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"trust":true,"type":"settings"}
{"cell_type":"code","end":1655230196107,"exec_count":1,"id":"ccb5e8","input":"%pip install torch torchvision\nimport torch\nimport torchvision\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.nn.functional as F","kernel":"cv_env","metadata":{"id":"ptEQDylSP4SP"},"no_halt":true,"output":{"0":{"name":"stdout","text":"Requirement already satisfied: torch in /projects/9f552ddb-0255-4438-a179-8f8c475cfce3/miniconda3/envs/cv_env/lib/python3.8/site-packages (1.11.0)\r\nRequirement already satisfied: torchvision in /projects/9f552ddb-0255-4438-a179-8f8c475cfce3/miniconda3/envs/cv_env/lib/python3.8/site-packages (0.12.0)\r\n"},"1":{"name":"stdout","text":"Requirement already satisfied: typing-extensions in /projects/9f552ddb-0255-4438-a179-8f8c475cfce3/miniconda3/envs/cv_env/lib/python3.8/site-packages (from torch) (4.2.0)\r\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /projects/9f552ddb-0255-4438-a179-8f8c475cfce3/miniconda3/envs/cv_env/lib/python3.8/site-packages (from torchvision) (9.1.1)\r\nRequirement already satisfied: requests in /projects/9f552ddb-0255-4438-a179-8f8c475cfce3/miniconda3/envs/cv_env/lib/python3.8/site-packages (from torchvision) (2.27.1)\r\nRequirement already satisfied: numpy in /projects/9f552ddb-0255-4438-a179-8f8c475cfce3/miniconda3/envs/cv_env/lib/python3.8/site-packages (from torchvision) (1.22.3)\r\n"},"2":{"name":"stdout","text":"Requirement already satisfied: certifi>=2017.4.17 in /projects/9f552ddb-0255-4438-a179-8f8c475cfce3/miniconda3/envs/cv_env/lib/python3.8/site-packages (from requests->torchvision) (2021.10.8)\r\nRequirement already satisfied: charset-normalizer~=2.0.0 in /projects/9f552ddb-0255-4438-a179-8f8c475cfce3/miniconda3/envs/cv_env/lib/python3.8/site-packages (from requests->torchvision) (2.0.12)\r\nRequirement already satisfied: idna<4,>=2.5 in /projects/9f552ddb-0255-4438-a179-8f8c475cfce3/miniconda3/envs/cv_env/lib/python3.8/site-packages (from requests->torchvision) (3.3)\r\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /projects/9f552ddb-0255-4438-a179-8f8c475cfce3/miniconda3/envs/cv_env/lib/python3.8/site-packages (from requests->torchvision) (1.26.9)\r\n"},"3":{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n"}},"pos":2,"start":1655230191590,"state":"done","type":"cell"}
{"cell_type":"code","end":1655230196129,"exec_count":2,"id":"f7c1a2","input":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","kernel":"cv_env","metadata":{"id":"8hk0-8XDGnpd"},"no_halt":true,"pos":6,"start":1655230196127,"state":"done","type":"cell"}
{"cell_type":"code","end":1655230196144,"exec_count":3,"id":"957cad","input":"# Convert Data to Tensors and normalize\ntransform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5), (0.5))])","kernel":"cv_env","metadata":{"id":"mgxEe11MLiry"},"no_halt":true,"pos":9,"start":1655230196142,"state":"done","type":"cell"}
{"cell_type":"code","end":1655230196158,"exec_count":4,"id":"9e933a","input":"# hyperparameters\ninput_size = 28 * 28 # 28 * 28 images\nnum_classes = 10 # 10 possible classifications/outputs for the model\nnum_epochs = 10 # 10 iterations over the dataset\nbatch_size = 8 # 8 images passed at a time into the model\n\n#the names of all the possible classifications\nclasses = (\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n           \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\")","kernel":"cv_env","metadata":{"id":"Zd-szzHtHCYb"},"no_halt":true,"pos":11,"start":1655230196157,"state":"done","type":"cell"}
{"cell_type":"code","end":1655230196294,"exec_count":5,"id":"49f68b","input":"# training set\ntrain_dataset = torchvision.datasets.FashionMNIST(\n    root = \"./data\",\n    train = True,\n    transform = transform,\n    download = True\n)\n\n# EXERCISE: do the same thing for the testing dataset and call it test_dataset\ntest_dataset = torchvision.datasets.FashionMNIST(\n    root = \"./data\",\n    train = False,\n    transform = transform,\n    download = True\n)","kernel":"cv_env","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423,"referenced_widgets":["0c32afe2a35c48dc81e26f43832e5528","80c324bd3a774d9fb3474fea9a2f37a1","d994ef5592444f078eb0b38adbb24176","bd1bcd5f50a248a896285f4a8e154c6c","86fbff3d1b4f4fe98ef4f5713c5c6014","35a8bff49c89404ba666f0181606edad","3e3ac696c1ae4030970a291d0b55a9c3","0dd8ab643bd24b2e949e4e3b4096d4be","5f4d3dce10394194943134f856a40b5e","68fbbf59d93340c7be0b57869ac17b15","fcbfca25f1a14e15b0fa0f6088bf40f1","d58ad2180cae45eab7addb2417b50a03","7280aea30eff49bf94a4217647cd70f2","7151b8796109496f9a0213d2ca556296","d841001138284dbe8628700df81bc404","683e7c41d782493ba3cb93d0c288ade1","fd2449e472514181a355fc1c315acfa2","b37cbc32dcbc49aca73006ba0f900a17","58493c17d71b43fc876c0cc4a3093120","161da13e65934d7f9ee9e5cd9f35a46f","a0acaa8f8ff04fa4aa8efef789ea6094","4b5790f98e3b44ec915349b854c9064f","9ddf7176f4d54ae4bca347af22041b7b","822c855d65d64f0a9112308d2389ff7c","67167b99eabd407d8a7900319b48c67f","52dd7ed840c244059a7d69252fb20a0f","14bbc869fe8d452692a6f7cdb38b075b","63bba93a02c141d18b53328db8173d67","f90246acab4b45f3b540772689ac3657","2cdcdd80797f42659fb44a03e3bbd269","71df07ea74d045ea93bba3d60dcb800c","76b8caf8fcbb48779f5dea6d2329ff4d","37a3453775974ecd9176a3c96dde77df","9e48ad9913664c5f9f53f3a815ba9c85","09985f7b880f47509081c7b8f6e797a6","499b378fe04d48aa937c21de79966c4b","701e7e3c57174353aa7190b10b10da27","53e1b8f46e04430c8e19fb66ec674d28","d71d754be2be425ca24b194a2aea125c","f6363bc40f524f2ea0ecb199cd4ad414","a41d6fc422ee47e189be9fde8a0fa2ff","20182c64d4de4aff830441867cfd9d78","d4b6729efbed4c48aa19ae019aa1ee43","c1528e5e1be64a93928ad41707b0dec0"]},"id":"dU6akcMoXxb3","outputId":"f2b71f90-d1c0-4798-9e2d-c83709954e8d"},"no_halt":true,"pos":13,"scrolled":true,"start":1655230196186,"state":"done","type":"cell"}
{"cell_type":"code","end":1655230197922,"exec_count":7,"id":"022b6d","input":"import matplotlib.pyplot as plt\nimport numpy as np\n\n#imshow wrapper function to display image\ndef imshow(img):\n    # EXERCISE: reverse normalization transform. Go up and see which operations were performed and do the opposite\n    img = img/2 + .5\n    \n    npimg = img.numpy() #turn the image tensor into a numpy array\n    plt.imshow(np.transpose(npimg, (1, 2, 0))) #transpose the array to  3x28x28 instead of 28x28x3\n    plt.show()\n\n\n# get some random training images\ndataiter = iter(trainloader)\nimages, labels = dataiter.next() #get the next batch of images from the iterator dataloader\n\n# show images\nimshow(torchvision.utils.make_grid(images)) #turn the batch of images into one image grid\n# print labels\nprint(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size))) #print out all the classifications for each image","kernel":"cv_env","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"id":"s2DfOJeRLbwk","outputId":"02498f6a-0dc8-41bc-80ad-84d0fa6fe42e"},"no_halt":true,"output":{"0":{"data":{"image/png":"416e43f0a5840891ae82133da03700685e706e5a","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"}},"1":{"name":"stdout","text":"Bag   Sneaker Sneaker Trouser Shirt Trouser Dress Pullover\n"}},"pos":19,"start":1655230196330,"state":"done","type":"cell"}
{"cell_type":"code","end":1655230565229,"exec_count":16,"id":"792c11","input":"# Get batched Dataloaders\ntrainloader = torch.utils.data.DataLoader(\n    dataset = train_dataset,\n    batch_size = batch_size,\n    shuffle = True # optional\n)\n\n#EXERCISE: Create a dataloader for the testing dataset called testloader\ntestloader = torch.utils.data.DataLoader(\n    dataset = test_dataset,\n    batch_size = batch_size,\n    shuffle = True\n)","kernel":"cv_env","metadata":{"id":"UA-UYjkpbYT3"},"pos":15,"start":1655230565225,"state":"done","type":"cell"}
{"cell_type":"code","end":1655230598119,"exec_count":18,"id":"eddf43","input":"class CNN(nn.Module):\n  def __init__(self):\n    super(CNN, self).__init__() \n    self.conv_layer_1 = nn.Sequential( # input.shape: [batch, 1, 28, 28]\n        nn.Conv2d(\n            in_channels=1, # grey scale, 3 otherwise if RGB   \n            out_channels=16, # 16 x 1(grey scale, 3 otherwise if RGB ) filters\n            kernel_size=5, # convolution extraction size\n            stride=1,\n            padding=2 # for convoluted output to be same size,\n                      # need padding=(kernel_size-1)/2 if stride = 1\n        ),\n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size=2) # (2x2 maxpool), out.shape: [16, 14, 14]\n    )\n    #EXERCISE: Code second convolutional group\n    self.fc = nn.Linear(32*7*7, 10)\n    self.conv_layer_2 = nn.Sequential(\n        nn.Conv2d(\n            in_channels = 16,\n            out_channels = 32,\n            kernel_size =5,\n            stride = 1,\n            padding = 2\n        ),\n        \n        nn.ReLU(),\n        nn.MaxPool2d(kernel_size = 2)\n    )\n    \n  def forward(self, x):\n    # x.shape: [batch_size, 1, 28, 28] -> [batch_size, 16, 14, 14]\n    x = self.conv_layer_1(x)\n    # x.shape: [batch_size, 16, 14, 14] -> [batch_size, 32, 7, 7]\n    x = self.conv_layer_2(x)\n    x = x.view(x.shape[0], -1) # flatten: [batch_size, 32*7*7]\n    # x.shape: [batch_size, 32*7*7] -> [batch_size, 10]\n    out = self.fc(x)\n    return out","kernel":"cv_env","metadata":{"id":"UslclwUyIU6p"},"pos":25,"start":1655230598077,"state":"done","type":"cell"}
{"cell_type":"code","end":1655230602146,"exec_count":19,"id":"5df56f","input":"model = CNN()\nmodel.to(device) # cast model to device\n\ncriterion = nn.CrossEntropyLoss()\n#EXERCISE: transfer the loss function over to the GPU. \ncriterion.to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.001)","kernel":"cv_env","metadata":{"id":"83YcVBTMNkE0"},"pos":29,"start":1655230602106,"state":"done","type":"cell"}
{"cell_type":"code","end":1655231212102,"exec_count":46,"id":"ca4143","input":"for epoch in range(3):  # loop over the dataset multiple times\n    running_loss = 0.0\n    for i, data in enumerate(trainloader):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n        inputs = inputs.to(device) # put input image onto gpu\n        labels = labels.to(device) # put label onto gpu\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = model(inputs)\n        #EXERCISE: Calculate \"loss\" by passing the outputs and labels into the loss function\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 3750 == 3749:    # print every 3750 mini-batches\n            #EXERCISE: print and reset total loss\n            print(\"Training loss: {}\".format(running_loss/3750))\n            running_loss = 0.0\n            \nprint('Finished Training')","kernel":"cv_env","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jm4C52vBNxBi","outputId":"7c1ac7da-1d31-483c-ff84-63eccb56d49b"},"output":{"0":{"name":"stdout","text":"Training loss: 0.45475432127844545\n"},"1":{"name":"stdout","text":"Training loss: 0.3236488519247621\n"},"2":{"name":"stdout","text":"Training loss: 0.281464719031301\n"},"3":{"name":"stdout","text":"Training loss: 0.26673561051955136\n"},"4":{"name":"stdout","text":"Training loss: 0.24451678128908194\n"},"5":{"name":"stdout","text":"Training loss: 0.24480962647934407\nFinished Training\n"}},"pos":31,"start":1655231079005,"state":"done","type":"cell"}
{"cell_type":"code","end":1655231520335,"exec_count":68,"id":"70bce9","input":"correct = 0\ntotal = 0\n# since we're not training, we don't need to calculate the gradients for our outputs\nwith torch.no_grad():\n    for data in testloader:\n        #EXERCISE: Split the data into image and labels as done in the training loop\n        inputs, labels = data\n\n        \n        #EXERCISE: Transfer the inputs and labels to the GPU\n        inputs = inputs.to(device) # put input image onto gpu\n        labels = labels.to(device) # put label onto gpu\n\n        \n        #EXERCISE: calculate outputs by running images through the network\n        outputs = model(inputs)\n        \n        # the class with the highest energy is what we choose as prediction\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')","kernel":"cv_env","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I6XAn4mNr8_W","outputId":"3a47fecd-91ad-4274-ef90-beb63ee1d07e"},"output":{"0":{"name":"stdout","text":"Accuracy of the network on the 10000 test images: 90 %\n"}},"pos":35,"start":1655231516067,"state":"done","type":"cell"}
{"cell_type":"code","end":1655231594661,"exec_count":71,"id":"ad9d46","input":"#EXERCISE: turn the test dataloader (called testloader) into an iterator and get the next image batch\ntestiter = iter(testloader)\nimages, labels = testiter.next()\n# print images\n#EXERCISE: Display the batch using torch.util.make_grid\nimshow(torchvision.utils.make_grid(images))\nprint('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))","kernel":"cv_env","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"id":"kZAICucFPRXx","outputId":"ddbe07f7-8dfc-46b0-cd04-6df452512447"},"output":{"0":{"data":{"image/png":"1041118d949e705ec5be71e64a855cbaae68dfc9","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"}},"1":{"name":"stdout","text":"GroundTruth:  Coat  Sandal Shirt Ankle boot Trouser Trouser T-shirt/top Sandal\n"}},"pos":33,"start":1655231594514,"state":"done","type":"cell"}
{"cell_type":"code","end":1655232060072,"exec_count":91,"id":"1a5acc","input":"import random\nrand = random.randint(0,9999)\nimage = test_dataset[rand][0] # shape: [(1) batch_size, 28, 28]\nplt.subplot()\nplt.axis('off')\n# [1, 28, 28] -> [28, 28]\nplt.imshow(image.squeeze(0))\nprint(f\"Ground Truth: {classes[test_dataset[rand][1]]}\")","kernel":"cv_env","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"Ra_kXL0EV2vf","outputId":"d91906ff-bf30-4466-b6c1-c3f63ec80dd3"},"output":{"0":{"name":"stdout","text":"Ground Truth: Dress\n"},"1":{"data":{"image/png":"4122a294f431be5887c1e38120d0997f370c3bf9","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"}}},"pos":37,"start":1655232059962,"state":"done","type":"cell"}
{"cell_type":"code","end":1655232062449,"exec_count":92,"id":"24a8ee","input":"with torch.no_grad():\n    # cast input to device\n    # [(1), 28, 28] -> [(1), (1), 28, 28]\n    image = image.to(device)\n\n    log_preds = model(image.unsqueeze(0))\n\n# post processes the image into more usable numbers\n#   Math: probabilites were natural logged, so torch.exp() performs e^(log_preds)\npreds = torch.exp(log_preds)\nprobab = list(preds.cpu().numpy()[0])\npred_label = probab.index(max(probab)) # get index of max num (highest probability)\n\nprint(f\"Prediction: {classes[pred_label]}\")","kernel":"cv_env","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rgE35PGOtMun","outputId":"56fb78f9-eaa4-4610-b407-7ecb6401208f"},"output":{"0":{"name":"stdout","text":"Prediction: Sneaker\n"}},"pos":38,"start":1655232062430,"state":"done","type":"cell"}
{"cell_type":"code","id":"58cd63","input":"","metadata":{"id":"TOpENCdFtSRZ"},"pos":39,"type":"cell"}
{"cell_type":"markdown","id":"033c90","input":"<h1>Preprocessing our Images</h1>\n\nThe transform that we will perform on our dataset is first converting all images to tensors. Tensors are the built in array datatype in pytorch, like numpy arrays. If you are interested, learn about why they are useful in keeping track of gradients here:\nhttps://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html .\n\nConverting to a tensor also converts an image with pixel values from 0 to 255 to a matrix with numbers from 0 to 1. \n\nIn addition, we are normalizing the data to a range between -1 and 1. If the range before is [0,1], subtracting 0.5 will give us [-0.5,0.5] and dividing by 0.5 will make the range wider to [-1,1]. torch.Normalize subtracts the first parameter from all the values in the image and divides by the second parameter. ","metadata":{"id":"Pz_N7lJRM5Zw"},"pos":7,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"03e94b","input":"matplotlib docs - https://matplotlib.org/stable/users/index","metadata":{"id":"4v-ygSOGM5Z2"},"pos":17,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"058cb6","input":"##### H2 = size of height after convolution\n##### W2 = size of width after convolution\n##### H1 = primitive height size\n##### FH = filter's height size\n##### W1 = primitive width size\n##### WH = filter's width size\n##### P = num padding\n##### S = stride","metadata":{"id":"3xjsirAPK5sL"},"pos":20,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"0901a1","input":"# Applying a neural network to the Fashion MNIST dataset\n\nUsing a grayscale image of a clothing article, how can we classify the type of clothing article? E.g shirt, pants, etc...","metadata":{"id":"u0BK-Hd1M5Za"},"pos":0,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"0a1835","input":"Module docs - https://pytorch.org/docs/stable/generated/torch.nn.Module.html <br> nn docs - https://pytorch.org/docs/stable/nn.html","metadata":{"id":"JvjaQMVAM5Z6"},"pos":26,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"0eed8c","input":"CUDA is the API that we will use for GPU training. If CUDA is available we want to use it, and otherwise use the CPU. If you are using Google colab, it comes with a built in GPU for use so make sure to activate it by going to Runtime->Change runtime type->GPU","metadata":{"id":"fZOnBmNTM5Zt"},"pos":5,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"1c06cf","input":"##### H2 = (H1 - FH + 2P)/S + 1\n##### W2 = (W1 - FW + 2P)/S + 1","metadata":{"id":"-Teg5776K9ZF"},"pos":21,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"344725","input":"Data format: [batch_size, 1(grey) (3 if RGB but not applicable here), 28, 28]","metadata":{"id":"mpRX_NL4Ict7"},"pos":23,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"4951af","input":"We first create a wrapper class for the pyplot imshow method, which is used to show RGB images on the screen. We first perform the opposite transformations as our initial normalization, to put the range of the pixels back between 0-1 (needed for pyplot. Next, we turn the tensor image into a numpy array and transpose the dimensions of image. \n\nWhy do we need to transpose the color channels? Because the tensor image is (28,28,3) so 28 by 28 which each unit having a third dimension of (R,G,B). We want it (3,28,28) so 3 distinct color channels with each channel being a different matrix (3 matrices). Finally, actually show the new image with plt.show(). \n\nThen we turn the train dataloader into an iterator and call the next() function to get the next batch of images and labels for display. Using the handy torch.utils.make_grid function, we can turn the images in the batch into one single row image, and at the end print out the classification/label for each image\n\n","metadata":{"id":"9H6KdGs7coRu"},"pos":18,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"4999b0","input":"## Dataloaders\n\nThe pytorch dataloader function creates an iterator that will give us one batch at a time as we iterate over the dataset. The parameters are self-explanatory, but the shuffle parameter shuffles the dataset. This is useful because we want to sample randomly and not go through all the data points from each classification one at a time. We wouldn't know the order of real world data. \n\n","metadata":{"id":"DyE4L-A6bnaD"},"pos":14,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"61b61c","input":"optim docs - https://pytorch.org/docs/stable/optim.html","metadata":{"id":"XBQj3ocPM5Z7"},"pos":27,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"640b83","input":"<h1>Creating Our Model</h1>","metadata":{"id":"cXZ3XWSbM5Z5"},"pos":22,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"710e07","input":"## Hyperparameters\n\ndatasets docs - https://pytorch.org/vision/stable/datasets.html\n\nThe input size is the number of pixels in each images, which is 28 by 28.\n\nThe number of classifcation (num_classes) is 10 because there are 10 possible classifications the model can make, such as T-shirt/top, trouser, bag, etc... \n\nThe number of epochs is how many times the training iterates over the dataset. For example, num_epochs of 8 means that the model will iterate over the dataset 10 times and each image is classified 10 times in training. More epochs means more training. If the loss is still going down after the last epoch, you should be training for more epochs. \n\nA batch size of 8 means 8 images at a time are passed into the model. A larger batch size means more images are passed at a time and there is faster training. Also, training is less variable, meaning it goes in a consistent image (think of it as using the average of the 8 images) while a batch size of 1 changes the weights for every image leading to more variable training. ","metadata":{"id":"gbhL7fcJM5Zz"},"pos":10,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"7982fb","input":"<h1>Evaluating our Model</h1>\n\n","metadata":{"id":"OcOQ9tIuM5Z9"},"pos":32,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"89391d","input":"## Training our Model\n\nThe training process goes somewhat like this\ngo through the dataset [epoch] times<br>\n&ensp;  go through each image in the dataset<br>\n&ensp;&ensp; transfer inputs and labels to GPU<br>\n&ensp;&ensp; get prediction for input<br>\n&ensp;&ensp; check if prediction matches label, get loss<br>\n&ensp;&ensp; see which direction you have to change the weights<br>\n&ensp;&ensp; actually change weights using optimizer and learning rate\n&ensp;&ensp; Set the directions back to zero (optim.zero_grad())<br>\n&ensp;&ensp; add loss to total loss until reset<br>\n&ensp;&ensp; after some iterations, print out loss and reset","metadata":{"id":"S4nlQyOVNmkk"},"pos":30,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"8b8b27","input":"# Applying the transforms\n\nWe are using the datasets.FashionMNIST function from torchvision to import the dataset. \n\n### Parameters to the function:\n\nThe root parameter sets the directory that we import the data to (and create it if it doesn't exist.)\n\nThe train parameter determines if we are importing training or testing fashion MNIST dataset. \n\nThe transform parameter determines the transforms we apply during preprocessing, which were defined above.\n\ndownload=True gives the function permission to download the data into the directory if it doesn't exist there. ","metadata":{"id":"4-lYAf_8Xtlu"},"pos":12,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"8caeb9","input":"## Evaluation Loop\nTurn off gradient descent using torch.no_grad. <br>\n&ensp; Iterate through every batch in the dataset<br>\n&ensp; Get the prediction of every image in the batch<br>\n&ensp; Add the number of images to the total<br>\n&ensp; Add the number of correctly classified images to a counter<br>\n&ensp; Get the accuracy through correct/total.<br>\n","metadata":{"id":"hJq4t5J_AvkE"},"pos":34,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"8e0f09","input":"## Import Dependencies\nPyTorch, or torch, is the python deep learning library we use for our neural networks. \n\nTorchvision is an extension of this tool for computer vision specific functions such as transforming images and image datasets. \n\ntorch.nn is the neural network specific part of the torch library and torch.nn.functional has the activation functions we want to use (such as ReLU). ","metadata":{"id":"qAQI1JtBH6NX"},"pos":1,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"8f4291","input":"transforms docs - https://pytorch.org/vision/stable/transforms.html","metadata":{"id":"E42dLkXJM5Zx"},"pos":8,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"9788af","input":"## Initializing the model, loss, and optimizer. \n\nFirst we initialize the model (our CNN). Next we transfer the CNN's weights over to the GPU. \n\nAfterward we initialize the cross entropy loss function, which is a loss function used for multi-class problems. Cross entropy heavily penalizes predictions that are far away from the true class distribution. \n\n","metadata":{"id":"uzj67dly8t-s"},"pos":28,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"aadfb9","input":"## Visualize our data","metadata":{"id":"PRFvX2ylDwaB"},"pos":16,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"acadf7","input":"GPU boost training time. Why? Because it lets us do hundreds to thousands of calculations at the same time","metadata":{"id":"eOCymhEgDh09"},"pos":4,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"c56705","input":"## Convolutional Neural Network\n\nFirst we create two main groups at the beginning, the first convolutional group and the second convolutional group. Each convolutional group has a convolutional layer, an activation function (RELU) and a pooling layer. \n\nRemember, the convolutional layer passes multiple filters over each channel and can change the number of channels. Into the convolutional layer we pass in the number of input channels and the number of output channels. The kernel size is the size of our filter (e.g 5x5 filter) and the stride is how many pixels to the right we move everytime we apply a filter. Finally, the padding determines how many layers of zeroes we add to the border. \n\nThe second convolutional group (the one you have the code) is only different in the number of input and output channels of the convolutional layer. Create a convolutional layer with 16 input channels (output of the previous group) and 32 output channels. ","metadata":{"id":"HcwyOu_561Dl"},"pos":24,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"d61398","input":"## Configure cuda/gpu if available","metadata":{"id":"dYu9n0fTDfet"},"pos":3,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"fe32ec","input":"<h1>Using our Model</h1>\n\nHere we simply pick a random image from our dataset and apply the model to it. ","metadata":{"id":"rXM79N49M5Z_"},"pos":36,"state":"done","type":"cell"}
{"id":0,"time":1655231210607,"type":"user"}
{"last_load":1655219610925,"type":"file"}